{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Infinite zoom - SD\n",
        "\n",
        "---\n",
        "\n",
        "[![An image](https://img.shields.io/static/v1?label=github&message=repository&color=blue&style=for-the-badge&logo=github&logoColor=white)](https://github.com/v8hid/infinite-zoom-stable-diffusion) \n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Intializing Environment { display-mode: \"form\" }\n",
        "\n",
        "%pip install gradio > /dev/null 2>&1\n",
        "%pip install -qq transformers scipy ftfy accelerate > /dev/null 2>&1\n",
        "%pip install -qq --upgrade diffusers[torch] > /dev/null 2>&1\n",
        "%pip install imageio[ffmpeg]\n",
        "%pip install imageio[pyav]\n",
        "!git clone https://github.com/v8hid/infinite-zoom-stable-diffusion.git\n",
        "\n",
        "import sys\n",
        "sys.path.extend(['infinite-zoom-stable-diffusion/'])\n",
        "from helpers import *\n",
        "from diffusers import StableDiffusionInpaintPipeline, EulerAncestralDiscreteScheduler\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import time"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ""
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBE5yk4uPD2q",
        "outputId": "6953590c-58aa-449a-b973-ba37ead24195",
        "gather": {
          "logged": 1681225818646
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define zoom functions { display-mode: \"form\" }\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "inpaint_model_list = [\n",
        "    \"stabilityai/stable-diffusion-2-inpainting\",\n",
        "    \"runwayml/stable-diffusion-inpainting\",\n",
        "    \"parlance/dreamlike-diffusion-1.0-inpainting\",\n",
        "    \"ghunkins/stable-diffusion-liberty-inpainting\",\n",
        "    \"ImNoOne/f222-inpainting-diffusers\"\n",
        "]\n",
        "default_prompt = \"A jungle with trees that have glowing, fractal-like patterns,salvador dali style, street level view, 8k resolution, hyper realistic\"\n",
        "default_negative_prompt = \"frames, borderline, text, charachter, duplicate, error, out of frame, watermark, low quality, ugly, deformed, blur,lowres, error, cropped, worst quality, low quality, jpeg artifacts, out of frame, watermark, signature\"\n",
        "\n",
        "def _repr_image_(self):\n",
        "    return self._repr_png_()\n",
        "\n",
        "# Set the `_repr_image_()` method for the `Image` class\n",
        "Image._repr_html_ = _repr_image_\n",
        "    \n",
        "def zoom(\n",
        "    model_id,\n",
        "    prompts_array,\n",
        "    negative_prompt,\n",
        "    num_outpainting_steps,\n",
        "    guidance_scale,\n",
        "    num_inference_steps,\n",
        "    custom_init_image\n",
        "):\n",
        "    prompts = {}\n",
        "    for x in prompts_array:\n",
        "        try:\n",
        "            key = int(x[0])\n",
        "            value = str(x[1])\n",
        "            prompts[key] = value\n",
        "        except ValueError:\n",
        "            pass\n",
        "    pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16,\n",
        "    )\n",
        "    pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(\n",
        "        pipe.scheduler.config)\n",
        "    pipe = pipe.to(\"cuda\")\n",
        "\n",
        "    def no_check(images, **kwargs):\n",
        "        return images, False\n",
        "    pipe.safety_checker = no_check\n",
        "    pipe.enable_attention_slicing()\n",
        "    g_cuda = torch.Generator(device='cuda')\n",
        "\n",
        "    height = 512\n",
        "    width = height\n",
        "\n",
        "    current_image = Image.new(mode=\"RGBA\", size=(height, width))\n",
        "    mask_image = np.array(current_image)[:, :, 3]\n",
        "    mask_image = Image.fromarray(255-mask_image).convert(\"RGB\")\n",
        "    current_image = current_image.convert(\"RGB\")\n",
        "    if (custom_init_image):\n",
        "        current_image = custom_init_image.resize(\n",
        "            (width, height), resample=Image.LANCZOS)\n",
        "    else:\n",
        "        init_images = pipe(prompt=prompts[min(k for k in prompts.keys() if k >= 0)],\n",
        "                           negative_prompt=negative_prompt,\n",
        "                           image=current_image,\n",
        "                           guidance_scale=guidance_scale,\n",
        "                           height=height,\n",
        "                           width=width,\n",
        "                           mask_image=mask_image,\n",
        "                           num_inference_steps=num_inference_steps)[0]\n",
        "        current_image = init_images[0]\n",
        "    mask_width = 128\n",
        "    num_interpol_frames = 30\n",
        "\n",
        "    all_frames = []\n",
        "    all_frames.append(current_image)\n",
        "\n",
        "    for i in range(num_outpainting_steps):\n",
        "        print('Outpaint step: ' + str(i+1) +\n",
        "              ' / ' + str(num_outpainting_steps))\n",
        "\n",
        "        prev_image_fix = current_image\n",
        "\n",
        "        prev_image = shrink_and_paste_on_blank(current_image, mask_width)\n",
        "\n",
        "        current_image = prev_image\n",
        "\n",
        "        # create mask (black image with white mask_width width edges)\n",
        "        mask_image = np.array(current_image)[:, :, 3]\n",
        "        mask_image = Image.fromarray(255-mask_image).convert(\"RGB\")\n",
        "\n",
        "        # inpainting step\n",
        "        current_image = current_image.convert(\"RGB\")\n",
        "        images = pipe(prompt=prompts[max(k for k in prompts.keys() if k <= i)],\n",
        "                      negative_prompt=negative_prompt,\n",
        "                      image=current_image,\n",
        "                      guidance_scale=guidance_scale,\n",
        "                      height=height,\n",
        "                      width=width,\n",
        "                      # generator = g_cuda.manual_seed(seed),\n",
        "                      mask_image=mask_image,\n",
        "                      num_inference_steps=num_inference_steps)[0]\n",
        "        current_image = images[0]\n",
        "        current_image.paste(prev_image, mask=prev_image)\n",
        "\n",
        "        # interpolation steps bewteen 2 inpainted images (=sequential zoom and crop)\n",
        "        for j in range(num_interpol_frames - 1):\n",
        "            interpol_image = current_image\n",
        "            interpol_width = round(\n",
        "                (1 - (1-2*mask_width/height)**(1-(j+1)/num_interpol_frames))*height/2\n",
        "            )\n",
        "            interpol_image = interpol_image.crop((interpol_width,\n",
        "                                                  interpol_width,\n",
        "                                                  width - interpol_width,\n",
        "                                                  height - interpol_width))\n",
        "\n",
        "            interpol_image = interpol_image.resize((height, width))\n",
        "\n",
        "            # paste the higher resolution previous image in the middle to avoid drop in quality caused by zooming\n",
        "            interpol_width2 = round(\n",
        "                (1 - (height-2*mask_width) / (height-2*interpol_width)) / 2*height\n",
        "            )\n",
        "            prev_image_fix_crop = shrink_and_paste_on_blank(\n",
        "                prev_image_fix, interpol_width2)\n",
        "            interpol_image.paste(prev_image_fix_crop, mask=prev_image_fix_crop)\n",
        "\n",
        "            all_frames.append(interpol_image)\n",
        "        all_frames.append(current_image)\n",
        "        #interpol_image.show()\n",
        "        display(interpol_image)\n",
        "    video_file_name = \"~/cloudfiles/code/Users/roberto.febrer/infinite-zoom-stable-diffusion/tmp/infinite_zoom_\" + str(time.time())\n",
        "    fps = 30\n",
        "    save_path = video_file_name + \".mp4\"\n",
        "    start_frame_dupe_amount = 15\n",
        "    last_frame_dupe_amount = 15\n",
        "\n",
        "    write_video(save_path, all_frames, fps, False,\n",
        "                start_frame_dupe_amount, last_frame_dupe_amount)\n",
        "    return save_path\n",
        "\n",
        "\n",
        "def zoom_app():\n",
        "    with gr.Blocks():\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "\n",
        "                outpaint_prompts = gr.Dataframe(\n",
        "                    type=\"array\",\n",
        "                    headers=[\"outpaint steps\", \"prompt\"],\n",
        "                    datatype=[\"number\", \"str\"],\n",
        "                    row_count=1,\n",
        "                    col_count=(2, \"fixed\"),\n",
        "                    value=[[0, default_prompt]],\n",
        "                    wrap=True\n",
        "                )\n",
        "\n",
        "                outpaint_negative_prompt = gr.Textbox(\n",
        "                    lines=1,\n",
        "                    value=default_negative_prompt,\n",
        "                    label='Negative Prompt'\n",
        "                )\n",
        "\n",
        "                outpaint_steps = gr.Slider(\n",
        "                    minimum=2,\n",
        "                    maximum=50,\n",
        "                    step=1,\n",
        "                    value=12,\n",
        "                    label='Total Outpaint Steps'\n",
        "                )\n",
        "                with gr.Accordion(\"Advanced Options\", open=False):\n",
        "                    model_id = gr.Dropdown(\n",
        "                        choices=inpaint_model_list,\n",
        "                        value=inpaint_model_list[0],\n",
        "                        label='Pre-trained Model ID'\n",
        "                    )\n",
        "\n",
        "                    guidance_scale = gr.Slider(\n",
        "                        minimum=0.1,\n",
        "                        maximum=15,\n",
        "                        step=0.1,\n",
        "                        value=7,\n",
        "                        label='Guidance Scale'\n",
        "                    )\n",
        "\n",
        "                    sampling_step = gr.Slider(\n",
        "                        minimum=1,\n",
        "                        maximum=100,\n",
        "                        step=1,\n",
        "                        value=50,\n",
        "                        label='Sampling Steps for each outpaint'\n",
        "                    )\n",
        "                    init_image = gr.Image(type=\"pil\",label=\"custom initial image\")\n",
        "                generate_btn = gr.Button(value='Generate video')\n",
        "\n",
        "            with gr.Column():\n",
        "                output_image = gr.Video(label='Output', format=\"mp4\").style(\n",
        "                    width=512, height=512)\n",
        "\n",
        "        generate_btn.click(\n",
        "            fn=zoom,\n",
        "            inputs=[\n",
        "                model_id,\n",
        "                outpaint_prompts,\n",
        "                outpaint_negative_prompt,\n",
        "                outpaint_steps,\n",
        "                guidance_scale,\n",
        "                sampling_step,\n",
        "                init_image\n",
        "            ],\n",
        "            outputs=output_image,\n",
        "        )\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "id": "5MJv55nPPTXY",
        "gather": {
          "logged": 1681225818881
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Launch App { display-mode: \"form\" }\n",
        "import gradio as gr\n",
        "\n",
        "app = gr.Blocks()\n",
        "with app:\n",
        "    gr.HTML(\n",
        "        \"\"\"\n",
        "        <h2 style='text-align: center'>\n",
        "        Text to Video - Infinite zoom effect\n",
        "        </h2>\n",
        "        \"\"\"\n",
        "    )\n",
        "    zoom_app()\n",
        "\n",
        "app.launch(share=False,debug=True,enable_queue=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ""
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "",
            "text/html": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "id": "Vhb-wxESGFGc",
        "gather": {
          "logged": 1681224896065
        }
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
